{
  "experiment": "external_dataset_validation",
  "description": "Testing frozen prediction rules on diverse real-world datasets",
  "results": [
    {
      "dataset": "Cora",
      "category": "high-h",
      "n_nodes": 2708,
      "n_edges": 5278,
      "n_classes": 7,
      "homophily": 0.8099659085273743,
      "mlp_acc": 0.7572744131088257,
      "gcn_acc": 0.8832412600517273,
      "sage_acc": 0.8839779257774353,
      "best_gnn_acc": 0.8839779257774353,
      "budget": 0.2427255868911743,
      "spi": 0.6199318170547485,
      "prediction": "GNN",
      "prediction_reason": "High-h trust region (h=0.81)",
      "actual_winner": "GNN",
      "prediction_correct": true,
      "gcn_advantage": 0.1259668469429016
    },
    {
      "dataset": "CiteSeer",
      "category": "high-h",
      "n_nodes": 3327,
      "n_edges": 4552,
      "n_classes": 6,
      "homophily": 0.7355008721351624,
      "mlp_acc": 0.7285285592079163,
      "gcn_acc": 0.7561561822891235,
      "sage_acc": 0.7555555820465087,
      "best_gnn_acc": 0.7561561822891235,
      "budget": 0.27147144079208374,
      "spi": 0.4710017442703247,
      "prediction": "MLP",
      "prediction_reason": "SPI (0.47) x Budget (0.27) <= 0.15",
      "actual_winner": "GNN",
      "prediction_correct": false,
      "gcn_advantage": 0.027627623081207253
    },
    {
      "dataset": "PubMed",
      "category": "high-h",
      "n_nodes": 19717,
      "n_edges": 44324,
      "n_classes": 3,
      "homophily": 0.8023869395256042,
      "mlp_acc": 0.8743914604187012,
      "gcn_acc": 0.8745943069458008,
      "sage_acc": 0.8907200694084167,
      "best_gnn_acc": 0.8907200694084167,
      "budget": 0.1256085395812988,
      "spi": 0.6047738790512085,
      "prediction": "GNN",
      "prediction_reason": "High-h trust region (h=0.80)",
      "actual_winner": "GNN",
      "prediction_correct": true,
      "gcn_advantage": 0.00020284652709956497
    },
    {
      "dataset": "Coauthor-CS",
      "category": "high-h",
      "n_nodes": 18333,
      "n_edges": 81894,
      "n_classes": 15,
      "homophily": 0.8080567717552185,
      "mlp_acc": 0.9439476013183594,
      "gcn_acc": 0.9400217771530152,
      "sage_acc": 0.9496182680130005,
      "best_gnn_acc": 0.9496182680130005,
      "budget": 0.05605239868164058,
      "spi": 0.616113543510437,
      "prediction": "GNN",
      "prediction_reason": "High-h trust region (h=0.81)",
      "actual_winner": "Tie",
      "prediction_correct": true,
      "gcn_advantage": -0.0039258241653442605
    },
    {
      "dataset": "Amazon-Computers",
      "category": "high-h",
      "n_nodes": 13752,
      "n_edges": 245861,
      "n_classes": 10,
      "homophily": 0.7772156000137329,
      "mlp_acc": 0.8273355603218079,
      "gcn_acc": 0.8980734705924988,
      "sage_acc": 0.6798982501029969,
      "best_gnn_acc": 0.8980734705924988,
      "budget": 0.17266443967819212,
      "spi": 0.5544312000274658,
      "prediction": "GNN",
      "prediction_reason": "High-h trust region (h=0.78)",
      "actual_winner": "GNN",
      "prediction_correct": true,
      "gcn_advantage": 0.07073791027069087
    },
    {
      "dataset": "Amazon-Photo",
      "category": "high-h",
      "n_nodes": 7650,
      "n_edges": 119081,
      "n_classes": 8,
      "homophily": 0.8272436261177063,
      "mlp_acc": 0.9197385668754577,
      "gcn_acc": 0.9379085183143616,
      "sage_acc": 0.9473202705383301,
      "best_gnn_acc": 0.9473202705383301,
      "budget": 0.08026143312454226,
      "spi": 0.6544872522354126,
      "prediction": "GNN",
      "prediction_reason": "High-h trust region (h=0.83)",
      "actual_winner": "GNN",
      "prediction_correct": true,
      "gcn_advantage": 0.018169951438903875
    },
    {
      "dataset": "Actor",
      "category": "low-h",
      "n_nodes": 7600,
      "n_edges": 15009,
      "n_classes": 5,
      "homophily": 0.21876144409179688,
      "mlp_acc": 0.3657894849777222,
      "gcn_acc": 0.2707894861698151,
      "sage_acc": 0.34921054244041444,
      "best_gnn_acc": 0.34921054244041444,
      "budget": 0.6342105150222779,
      "spi": 0.5624771118164062,
      "prediction": "GNN",
      "prediction_reason": "Low-h trust region (h=0.22)",
      "actual_winner": "MLP",
      "prediction_correct": false,
      "gcn_advantage": -0.0949999988079071
    },
    {
      "dataset": "Wikipedia-chameleon",
      "category": "low-h",
      "n_nodes": 2277,
      "n_edges": 18050,
      "n_classes": 5,
      "homophily": 0.23500734567642212,
      "mlp_acc": 0.5087719202041626,
      "gcn_acc": 0.379824560880661,
      "sage_acc": 0.5276315808296204,
      "best_gnn_acc": 0.5276315808296204,
      "budget": 0.4912280797958374,
      "spi": 0.5299853086471558,
      "prediction": "GNN",
      "prediction_reason": "Low-h trust region (h=0.24)",
      "actual_winner": "GNN",
      "prediction_correct": true,
      "gcn_advantage": -0.1289473593235016
    },
    {
      "dataset": "Wikipedia-squirrel",
      "category": "low-h",
      "n_nodes": 5201,
      "n_edges": 108536,
      "n_classes": 5,
      "homophily": 0.2239430993795395,
      "mlp_acc": 0.34716618061065674,
      "gcn_acc": 0.2624399572610855,
      "sage_acc": 0.3767531156539917,
      "best_gnn_acc": 0.3767531156539917,
      "budget": 0.6528338193893433,
      "spi": 0.552113801240921,
      "prediction": "GNN",
      "prediction_reason": "Low-h trust region (h=0.22)",
      "actual_winner": "GNN",
      "prediction_correct": true,
      "gcn_advantage": -0.08472622334957125
    }
  ],
  "summary": {
    "total_datasets": 9,
    "correct_predictions": 7,
    "accuracy": 0.7777777777777778
  }
}